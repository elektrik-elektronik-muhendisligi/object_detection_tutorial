{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_image_classification_web_demo",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lvisdd/object_detection_tutorial/blob/master/keras_image_classification_web_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmUuQVD5_SXk",
        "colab_type": "code",
        "outputId": "5ae09595-0013-4c43-ee8e-a67d3098ef07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "import os\n",
        "from imageio import imread, imsave\n",
        "from PIL import Image"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw0ijtnvs2_y",
        "colab_type": "text"
      },
      "source": [
        "## [Models for image classification with weights trained on ImageNet](https://keras.io/applications/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lG5hphsrb3fZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = \"MobileNetV2\" #@param [\"Xception\", \"VGG16\", \"VGG19\", \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"MobileNet\", \"MobileNetV2\", \"DenseNet121\", \"DenseNet169\", \"DenseNet201\", \"NASNetLarge\", \"NASNetMobile\"] {allow-input: true}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtGODg2ifcb0",
        "colab_type": "code",
        "outputId": "2425053e-819b-4a10-f817-f4e0a9fd20d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "if model_name == \"Xception\":\n",
        "    from keras.applications.xception import Xception\n",
        "    from keras.applications.xception import preprocess_input, decode_predictions\n",
        "    model = Xception(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,299,299,3))))\n",
        "    h, w = 299, 299\n",
        "elif model_name == \"VGG16\":\n",
        "    from keras.applications.vgg16 import VGG16\n",
        "    from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "    model = VGG16(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"VGG19\":\n",
        "    from keras.applications.vgg19 import VGG19\n",
        "    from keras.applications.vgg19 import preprocess_input, decode_predictions\n",
        "    model = VGG19(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"ResNet50\":\n",
        "    from keras.applications.resnet50 import ResNet50\n",
        "    from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "    model = ResNet50(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"InceptionV3\":\n",
        "    from keras.applications.inception_v3 import InceptionV3\n",
        "    from keras.applications.inception_v3 import preprocess_input, decode_predictions\n",
        "    model = InceptionV3(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,299,299,3))))\n",
        "    h, w = 299, 299\n",
        "elif model_name == \"InceptionResNetV2\":\n",
        "    from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "    from keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n",
        "    model = InceptionResNetV2(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,299,299,3))))\n",
        "    h, w = 299, 299\n",
        "elif model_name == \"MobileNet\":\n",
        "    from keras.applications.mobilenet import MobileNet\n",
        "    from keras.applications.mobilenet import preprocess_input, decode_predictions\n",
        "    model = MobileNet(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"MobileNetV2\":\n",
        "    from keras.applications.mobilenetv2 import MobileNetV2\n",
        "    from keras.applications.mobilenetv2 import preprocess_input, decode_predictions\n",
        "    model = MobileNetV2(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"DenseNet121\":\n",
        "    from keras.applications.densenet import DenseNet121\n",
        "    from keras.applications.densenet import preprocess_input, decode_predictions\n",
        "    model = DenseNet121(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"DenseNet169\":\n",
        "    from keras.applications.densenet import DenseNet169\n",
        "    from keras.applications.densenet import preprocess_input, decode_predictions\n",
        "    model = DenseNet169(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"DenseNet201\":\n",
        "    from keras.applications.densenet import DenseNet201\n",
        "    from keras.applications.densenet import preprocess_input, decode_predictions\n",
        "    model = DenseNet201(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "elif model_name == \"NASNetLarge\":\n",
        "    from keras.applications.nasnet import NASNetLarge\n",
        "    from keras.applications.nasnet import preprocess_input, decode_predictions\n",
        "    model = NASNetLarge(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,331,331,3))))\n",
        "    h, w = 331, 331\n",
        "elif model_name == \"NASNetMobile\":\n",
        "    from keras.applications.nasnet import NASNetMobile\n",
        "    from keras.applications.nasnet import preprocess_input, decode_predictions\n",
        "    model = NASNetMobile(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224\n",
        "else:\n",
        "    from keras.applications.vgg16 import VGG16\n",
        "    from keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "    model = VGG16(weights='imagenet')\n",
        "    preds = model.predict(preprocess_input(np.zeros((1,224,224,3))))\n",
        "    h, w = 224, 224"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 06:07:12.542532 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0808 06:07:12.560870 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0808 06:07:12.568646 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0808 06:07:12.597304 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0808 06:07:12.598468 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0808 06:07:13.196358 139676677666688 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG7yVH0eA5Fz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def imageResize(img, h, w):\n",
        "    ih, iw = img.shape[0], img.shape[1]\n",
        "    if ih >= iw:\n",
        "        dst = np.ones([ih, ih, 3], np.uint8) * 255\n",
        "        dst[:, (ih - iw)//2:(ih - iw)//2 + iw] = img\n",
        "    else:\n",
        "        dst = np.ones([iw, iw, 3], np.uint8) * 255\n",
        "        dst[(iw - ih)//2:(iw - ih)//2 + ih, :] = img\n",
        "        \n",
        "    dst = np.array(Image.fromarray(dst).resize((w, h)))\n",
        "    return dst        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuwxFZLCxor7",
        "colab_type": "text"
      },
      "source": [
        "## Write Static Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZNjhzo5CcgD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Writing to html file on colab\n",
        "\n",
        "html = \"\"\"\n",
        "\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "<meta charset=\"utf-8\" />\n",
        "</head>\n",
        "<body>\n",
        "\n",
        "<form action=\"/post\" method=\"post\" enctype=\"multipart/form-data\">\n",
        "    <p><input type=\"file\" name=\"uploadFile\"/></p>\n",
        "    <p><input type=\"submit\" value=\"send\"/></p>\n",
        "</form>\n",
        "\n",
        "{% if ulr_Image %}\n",
        "\n",
        "    <p>Image</p>\n",
        "    <p><img src=\"{{ ulr_Image }}\"></p>\n",
        "    <p>Result</p>\n",
        "    <p>{{ result_class }}</p>\n",
        "    <p>{{ result_score }}</p>\n",
        "\n",
        "{% endif %}\n",
        "\n",
        "</body>\n",
        "</html>\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Saving html file\n",
        "if not os.path.isdir( \"templates\" ):\n",
        "    os.makedirs( \"templates\" )\n",
        "with open(\"templates/index.html\", mode='w') as f:\n",
        "    f.write(html)\n",
        "\n",
        "# Saving favicon file\n",
        "if not os.path.isdir( \"static\" ):\n",
        "    os.makedirs( \"static\" )\n",
        "with open(\"static/favicon.ico\", mode='w') as f:\n",
        "    f.close()\n",
        "\n",
        "# Making tmp folder to use temporarily stored\n",
        "if not os.path.isdir( \"tmp\" ):\n",
        "    os.makedirs( \"tmp\" )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONMxxraTvrxw",
        "colab_type": "text"
      },
      "source": [
        "## Install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_pOuaKLCbvp",
        "colab_type": "code",
        "outputId": "761e04d2-d201-4970-f098-095d9cd4bf88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-08 06:07:28--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 54.165.51.142, 34.196.237.103, 52.4.11.55, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|54.165.51.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13607069 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.6’\n",
            "\n",
            "\r          ngrok-sta   0%[                    ]       0  --.-KB/s               \r         ngrok-stab   0%[                    ]  97.94K   398KB/s               \r        ngrok-stabl   6%[>                   ] 884.64K  1.75MB/s               \r       ngrok-stable  46%[========>           ]   6.08M  8.23MB/s               \rngrok-stable-linux- 100%[===================>]  12.98M  14.3MB/s    in 0.9s    \n",
            "\n",
            "2019-08-08 06:07:29 (14.3 MB/s) - ‘ngrok-stable-linux-amd64.zip.6’ saved [13607069/13607069]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: ngrok                   \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zd__AVXhim7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c3f476f8-39f3-4811-b6a2-a3c99b56ad89"
      },
      "source": [
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://1356c1ce.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3VH0mZvys4i",
        "colab_type": "text"
      },
      "source": [
        "## Serve Flask app and Click ngrok URL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UW61J_fC9Yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e4fe7075-4ede-4e53-8143-e9a0b184865f"
      },
      "source": [
        "from flask import Flask, render_template, send_from_directory, request, redirect, url_for\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\")\n",
        "def index():\n",
        "    return render_template( \"index.html\" )\n",
        "\n",
        "@app.route('/favicon.ico')\n",
        "def favicon():\n",
        "    return send_from_directory(os.path.join(app.root_path, 'static'),\n",
        "                               'favicon.ico', mimetype='image/vnd.microsoft.icon')\n",
        "\n",
        "@app.route('/post', methods=['POST'])\n",
        "def post():\n",
        "    try:\n",
        "        uploadFile = request.files['uploadFile']\n",
        "    except:\n",
        "        return redirect(url_for('index'))\n",
        "    \n",
        "    uploadFile.save(\"tmp/\" + uploadFile.filename)\n",
        "    \n",
        "    img = imread(\"tmp/\" + uploadFile.filename)\n",
        "    if img.shape[-1] == 4:\n",
        "        img = img[:,:,0:3]\n",
        "    img = imageResize(img, h, w)\n",
        "    fileName = str(np.random.randint(1000)) + \".jpg\"\n",
        "    imsave(\"tmp/\" + fileName, img)\n",
        "    ulr_Image = \"tmp/\" + fileName\n",
        "    \n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    # print(img.shape)\n",
        "    preds = model.predict(preprocess_input(img))\n",
        "    result = decode_predictions(preds, top=1)[0][0]\n",
        "    result_class = \"Class: \" + result[1]\n",
        "    result_score = \"Score: \" + str(result[2])\n",
        "    \n",
        "    return render_template( \"index.html\",\n",
        "                            ulr_Image = ulr_Image,\n",
        "                            result_class = result_class,\n",
        "                            result_score = result_score)\n",
        "\n",
        "@app.route('/tmp/<filename>')\n",
        "def uploaded_file(filename):\n",
        "    return send_from_directory(\"./tmp\", filename)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(port=6006)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "   WARNING: This is a development server. Do not use it in a production deployment.\n",
            "   Use a production WSGI server instead.\n",
            " * Debug mode: off\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I0808 06:07:46.448993 139676677666688 _internal.py:122]  * Running on http://127.0.0.1:6006/ (Press CTRL+C to quit)\n",
            "I0808 06:07:54.463778 139674082301696 _internal.py:122] 127.0.0.1 - - [08/Aug/2019 06:07:54] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
            "I0808 06:07:55.023090 139674082301696 _internal.py:122] 127.0.0.1 - - [08/Aug/2019 06:07:55] \"\u001b[37mGET /favicon.ico HTTP/1.1\u001b[0m\" 200 -\n",
            "I0808 06:08:00.584001 139674082301696 _internal.py:122] 127.0.0.1 - - [08/Aug/2019 06:08:00] \"\u001b[37mPOST /post HTTP/1.1\u001b[0m\" 200 -\n",
            "I0808 06:08:00.886874 139674082301696 _internal.py:122] 127.0.0.1 - - [08/Aug/2019 06:08:00] \"\u001b[37mGET /tmp/324.jpg HTTP/1.1\u001b[0m\" 200 -\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}